########## Setting Up Experiment ######################

Putting log in RNN_ADAM_model=RNN_optimizer=ADAM_initial_lr=0.0001_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_4
Using the GPU
Loading data from data
  vocabulary size: 10000

########## Running Main Loop ##########################

EPOCH 0 ------------------
step: 10	loss: 3420.4675722122192	speed (wps):6275.624717878904
step: 142	loss: 36347.63960599899	speed (wps):6447.008401091826
step: 274	loss: 67526.47746562958	speed (wps):6452.67234813705
step: 406	loss: 97860.85681200027	speed (wps):6455.065759137272
step: 538	loss: 127934.4213604927	speed (wps):6455.890464629786
step: 670	loss: 157750.0337767601	speed (wps):6455.8696895867615
step: 802	loss: 186973.19202899933	speed (wps):6456.13365554273
step: 934	loss: 216093.39445352554	speed (wps):6456.252556748099
step: 1066	loss: 245034.97271299362	speed (wps):6456.378820249351
step: 1198	loss: 273691.1357951164	speed (wps):6456.412690201921
Saving model parameters to best_params.pt
epoch: 0	train ppl: 657.22556988	val ppl: 399.331374212	best val: 399.331374212	time (s) spent in epoch: 146.51058769226074

EPOCH 1 ------------------
step: 10	loss: 2419.5648741722107	speed (wps):6315.658093945201
step: 142	loss: 30525.402743816376	speed (wps):6444.543820743709
step: 274	loss: 58976.47745370865	speed (wps):6449.870378461151
step: 406	loss: 87062.43738174438	speed (wps):6451.183812755605
step: 538	loss: 115200.23140668869	speed (wps):6452.047662988416
step: 670	loss: 143310.2464747429	speed (wps):6452.446490649391
step: 802	loss: 170932.9686808586	speed (wps):6452.707813665526
step: 934	loss: 198596.475148201	speed (wps):6452.818097516043
step: 1066	loss: 226242.3116850853	speed (wps):6453.066931357452
step: 1198	loss: 253621.48342370987	speed (wps):6453.249691873072
Saving model parameters to best_params.pt
epoch: 1	train ppl: 416.46105322	val ppl: 317.924596108	best val: 317.924596108	time (s) spent in epoch: 146.65449142456055

EPOCH 2 ------------------
step: 10	loss: 2333.5674619674683	speed (wps):6091.733378803591
step: 142	loss: 29392.279646396637	speed (wps):6422.73035249889
step: 274	loss: 56896.93563222885	speed (wps):6436.950954155428
step: 406	loss: 84089.86303806305	speed (wps):6441.824127062895
step: 538	loss: 111361.86358213425	speed (wps):6443.957926053566
step: 670	loss: 138627.16772794724	speed (wps):6445.358298382261
step: 802	loss: 165468.96448373795	speed (wps):6446.410682164356
step: 934	loss: 192394.04099941254	speed (wps):6447.190390858263
step: 1066	loss: 219297.80335903168	speed (wps):6447.861470962196
step: 1198	loss: 245988.9148235321	speed (wps):6448.202490960566
Saving model parameters to best_params.pt
epoch: 2	train ppl: 348.457651472	val ppl: 278.757588884	best val: 278.757588884	time (s) spent in epoch: 146.7616958618164

EPOCH 3 ------------------
step: 10	loss: 2278.023200035095	speed (wps):6117.103457315131
step: 142	loss: 28716.84062242508	speed (wps):6422.846489531674
step: 274	loss: 55628.61838579178	speed (wps):6436.705458184445
step: 406	loss: 82236.27919197083	speed (wps):6441.214797965519
step: 538	loss: 108981.24821424484	speed (wps):6443.922214034821
step: 670	loss: 135739.28397417068	speed (wps):6445.463903533008
step: 802	loss: 162077.6634836197	speed (wps):6446.444190034506
step: 934	loss: 188477.6879286766	speed (wps):6446.978945511614
step: 1066	loss: 214881.7728638649	speed (wps):6447.477094597524
step: 1198	loss: 241074.71558332443	speed (wps):6447.983810895671
Saving model parameters to best_params.pt
epoch: 3	train ppl: 310.38424011	val ppl: 254.421992429	best val: 254.421992429	time (s) spent in epoch: 146.71869039535522

EPOCH 4 ------------------
step: 10	loss: 2241.743531227112	speed (wps):6310.192765232193
step: 142	loss: 28243.558444976807	speed (wps):6439.74209485869
step: 274	loss: 54767.664852142334	speed (wps):6444.983766239079
step: 406	loss: 80953.19683790207	speed (wps):6447.411379274938
step: 538	loss: 107277.52338886261	speed (wps):6448.173542873476
step: 670	loss: 133602.90006399155	speed (wps):6448.807268040194
step: 802	loss: 159507.4663066864	speed (wps):6448.9996225548175
step: 934	loss: 185543.62169265747	speed (wps):6449.0748427875715
step: 1066	loss: 211596.29524707794	speed (wps):6449.356522251837
step: 1198	loss: 237420.50360918045	speed (wps):6449.417211866964
Saving model parameters to best_params.pt
epoch: 4	train ppl: 284.736963935	val ppl: 238.054752844	best val: 238.054752844	time (s) spent in epoch: 146.74129247665405

EPOCH 5 ------------------
step: 10	loss: 2215.420298576355	speed (wps):6122.340264600114
step: 142	loss: 27843.958644866943	speed (wps):6421.103303672367
step: 274	loss: 54021.58736228943	speed (wps):6434.000444258064
step: 406	loss: 79868.68378162384	speed (wps):6438.924352048181
step: 538	loss: 105843.65996360779	speed (wps):6441.337201321881
step: 670	loss: 131837.0360994339	speed (wps):6442.646267148487
step: 802	loss: 157428.92038583755	speed (wps):6443.804358159602
step: 934	loss: 183157.62387514114	speed (wps):6444.479536421683
step: 1066	loss: 208899.8898410797	speed (wps):6444.939383884024
step: 1198	loss: 234409.74870204926	speed (wps):6445.204459441945
Saving model parameters to best_params.pt
epoch: 5	train ppl: 265.152532305	val ppl: 224.821791053	best val: 224.821791053	time (s) spent in epoch: 146.83860063552856

EPOCH 6 ------------------
step: 10	loss: 2193.6380910873413	speed (wps):6114.505776247854
step: 142	loss: 27516.434392929077	speed (wps):6422.284511770116
step: 274	loss: 53418.98206472397	speed (wps):6434.245785204869
step: 406	loss: 78955.01088380814	speed (wps):6438.779674683852
step: 538	loss: 104643.49856615067	speed (wps):6440.705584551035
step: 670	loss: 130386.76215171814	speed (wps):6441.9000192148715
step: 802	loss: 155724.57490205765	speed (wps):6442.639528185358
step: 934	loss: 181187.81347036362	speed (wps):6443.316337242574
step: 1066	loss: 206657.53494739532	speed (wps):6443.869058592401
step: 1198	loss: 231888.75760793686	speed (wps):6444.2683762696
Saving model parameters to best_params.pt
epoch: 6	train ppl: 249.981851144	val ppl: 215.188176598	best val: 215.188176598	time (s) spent in epoch: 146.80517578125

EPOCH 7 ------------------
step: 10	loss: 2174.3383169174194	speed (wps):6273.286687912923
step: 142	loss: 27252.301127910614	speed (wps):6435.996490023619
step: 274	loss: 52907.451848983765	speed (wps):6440.7853061965425
step: 406	loss: 78219.96845960617	speed (wps):6442.927205902731
step: 538	loss: 103681.5061545372	speed (wps):6443.957611177313
step: 670	loss: 129169.21893119812	speed (wps):6444.734122001824
step: 802	loss: 154252.82861709595	speed (wps):6445.194587543823
step: 934	loss: 179483.79549741745	speed (wps):6445.712834827084
step: 1066	loss: 204733.32435131073	speed (wps):6446.099382741707
step: 1198	loss: 229741.32736682892	speed (wps):6446.381798523678
Saving model parameters to best_params.pt
epoch: 7	train ppl: 237.438603544	val ppl: 206.927995559	best val: 206.927995559	time (s) spent in epoch: 146.8077850341797

EPOCH 8 ------------------
step: 10	loss: 2161.275534629822	speed (wps):6193.694564124673
step: 142	loss: 27014.434068202972	speed (wps):6426.765086448712
step: 274	loss: 52451.194677352905	speed (wps):6436.881932179302
step: 406	loss: 77510.72685956955	speed (wps):6440.653871264796
step: 538	loss: 102737.73518800735	speed (wps):6442.469193963092
step: 670	loss: 127977.83620595932	speed (wps):6443.124847506128
step: 802	loss: 152852.75141239166	speed (wps):6443.8354260580745
step: 934	loss: 177927.0675945282	speed (wps):6444.443076080528
step: 1066	loss: 203007.38474845886	speed (wps):6444.662637768219
step: 1198	loss: 227807.45062828064	speed (wps):6444.950123925823
Saving model parameters to best_params.pt
epoch: 8	train ppl: 226.871790224	val ppl: 205.526359049	best val: 205.526359049	time (s) spent in epoch: 146.82328915596008

EPOCH 9 ------------------
step: 10	loss: 2135.255696773529	speed (wps):6276.32597885461
step: 142	loss: 26762.34355211258	speed (wps):6433.426753541228
step: 274	loss: 52007.64574050903	speed (wps):6440.762339793516
step: 406	loss: 76876.72478199005	speed (wps):6442.599288862531
step: 538	loss: 101918.19867372513	speed (wps):6444.128541028317
step: 670	loss: 127005.3393983841	speed (wps):6444.701443732959
step: 802	loss: 151654.71876859665	speed (wps):6445.122893770821
step: 934	loss: 176520.63109874725	speed (wps):6445.309597334445
step: 1066	loss: 201409.88446712494	speed (wps):6445.599756643207
step: 1198	loss: 226017.95564889908	speed (wps):6445.727424245111
Saving model parameters to best_params.pt
epoch: 9	train ppl: 217.543010676	val ppl: 196.030121426	best val: 196.030121426	time (s) spent in epoch: 146.820538520813

EPOCH 10 ------------------
step: 10	loss: 2131.4366006851196	speed (wps):6127.656965028148
step: 142	loss: 26583.828184604645	speed (wps):6422.30936640011
step: 274	loss: 51675.586121082306	speed (wps):6434.985766820373
step: 406	loss: 76375.20026922226	speed (wps):6438.815513818419
step: 538	loss: 101231.99311494827	speed (wps):6440.747499744478
step: 670	loss: 126142.29381084442	speed (wps):6442.040879419491
step: 802	loss: 150620.0077033043	speed (wps):6443.05906497153
step: 934	loss: 175329.67313289642	speed (wps):6443.699193661116
step: 1066	loss: 200033.9642572403	speed (wps):6444.13669606245
step: 1198	loss: 224469.26075696945	speed (wps):6444.334180384824
Saving model parameters to best_params.pt
epoch: 10	train ppl: 209.710028954	val ppl: 191.649680755	best val: 191.649680755	time (s) spent in epoch: 146.82734632492065

EPOCH 11 ------------------
step: 10	loss: 2113.2018542289734	speed (wps):6284.13090688899
step: 142	loss: 26397.30791091919	speed (wps):6434.661611913654
step: 274	loss: 51322.83373832703	speed (wps):6440.410054669463
step: 406	loss: 75839.10118341446	speed (wps):6442.672997814298
step: 538	loss: 100531.72501802444	speed (wps):6443.854307188126
step: 670	loss: 125290.51265001297	speed (wps):6444.441231125316
step: 802	loss: 149616.93150758743	speed (wps):6445.019029607667
step: 934	loss: 174171.471824646	speed (wps):6445.195407585623
step: 1066	loss: 198712.91900157928	speed (wps):6445.533620446478
step: 1198	loss: 223000.04141569138	speed (wps):6445.69114417118
Saving model parameters to best_params.pt
epoch: 11	train ppl: 202.462573813	val ppl: 186.565143683	best val: 186.565143683	time (s) spent in epoch: 146.76412057876587

EPOCH 12 ------------------
step: 10	loss: 2097.8660225868225	speed (wps):6277.268964525305
step: 142	loss: 26232.465102672577	speed (wps):6434.187588742134
step: 274	loss: 51015.155584812164	speed (wps):6440.911958318595
step: 406	loss: 75390.33487081528	speed (wps):6443.106983912172
step: 538	loss: 99954.86445188522	speed (wps):6444.588658707324
step: 670	loss: 124556.95402145386	speed (wps):6445.2082682610835
step: 802	loss: 148750.61146259308	speed (wps):6445.555194935456
step: 934	loss: 173162.51981019974	speed (wps):6445.8785180874465
step: 1066	loss: 197572.46606349945	speed (wps):6445.954530814496
step: 1198	loss: 221707.5402379036	speed (wps):6445.945042447007
Saving model parameters to best_params.pt
epoch: 12	train ppl: 196.368013278	val ppl: 183.898699517	best val: 183.898699517	time (s) spent in epoch: 146.82133865356445

EPOCH 13 ------------------
step: 10	loss: 2087.68723487854	speed (wps):6191.747159412254
step: 142	loss: 26082.86010980606	speed (wps):6426.736262296544
step: 274	loss: 50715.313341617584	speed (wps):6437.460376982223
step: 406	loss: 74963.29720973969	speed (wps):6440.273564592167
step: 538	loss: 99384.53489303589	speed (wps):6441.922395621476
step: 670	loss: 123857.10594415665	speed (wps):6442.805680683421
step: 802	loss: 147899.79719638824	speed (wps):6443.595925669576
step: 934	loss: 172195.04289388657	speed (wps):6444.011196149516
step: 1066	loss: 196497.67122030258	speed (wps):6444.448024412596
step: 1198	loss: 220495.4513978958	speed (wps):6444.738035679519
Saving model parameters to best_params.pt
epoch: 13	train ppl: 190.824295875	val ppl: 181.225809567	best val: 181.225809567	time (s) spent in epoch: 146.84759426116943

EPOCH 14 ------------------
step: 10	loss: 2079.0450978279114	speed (wps):6109.062789943243
step: 142	loss: 25928.803079128265	speed (wps):6421.728132783252
step: 274	loss: 50441.37038946152	speed (wps):6434.7704212793315
step: 406	loss: 74552.67447710037	speed (wps):6439.130936225776
step: 538	loss: 98854.28667545319	speed (wps):6440.914064947728
step: 670	loss: 123189.20422554016	speed (wps):6442.157182729706
step: 802	loss: 147103.33030223846	speed (wps):6443.150134982758
step: 934	loss: 171279.64560747147	speed (wps):6443.710083819389
step: 1066	loss: 195433.90883922577	speed (wps):6444.169305584188
step: 1198	loss: 219284.78692293167	speed (wps):6444.544047627728
Saving model parameters to best_params.pt
epoch: 14	train ppl: 185.383746401	val ppl: 179.031744419	best val: 179.031744419	time (s) spent in epoch: 146.84293746948242

EPOCH 15 ------------------
step: 10	loss: 2071.1537289619446	speed (wps):6291.444152475297
step: 142	loss: 25781.20233774185	speed (wps):6435.033720218722
step: 274	loss: 50162.7961230278	speed (wps):6440.739065283721
step: 406	loss: 74123.11541318893	speed (wps):6443.531299794912
step: 538	loss: 98258.6658835411	speed (wps):6445.073279611944
step: 670	loss: 122441.468770504	speed (wps):6445.554012261326
step: 802	loss: 146232.243142128	speed (wps):6445.725389561123
step: 934	loss: 170282.721889019	speed (wps):6446.005930630218
step: 1066	loss: 194327.19867944717	speed (wps):6446.360984229092
step: 1198	loss: 218056.5590953827	speed (wps):6446.467903148693
Saving model parameters to best_params.pt
epoch: 15	train ppl: 180.1405954	val ppl: 177.661784271	best val: 177.661784271	time (s) spent in epoch: 146.76824045181274

EPOCH 16 ------------------
step: 10	loss: 2060.844180583954	speed (wps):6235.276964327637
step: 142	loss: 25687.60401725769	speed (wps):6429.322512527268
step: 274	loss: 49974.73292350769	speed (wps):6438.241296082335
step: 406	loss: 73822.46896266937	speed (wps):6440.853206556418
step: 538	loss: 97868.55485200882	speed (wps):6442.329928597289
step: 670	loss: 121956.75160169601	speed (wps):6443.389400441439
step: 802	loss: 145657.66865968704	speed (wps):6444.083698213031
step: 934	loss: 169623.70094776154	speed (wps):6444.645489136872
step: 1066	loss: 193573.70611667633	speed (wps):6444.867003059348
step: 1198	loss: 217195.39549350739	speed (wps):6445.20882558829
Saving model parameters to best_params.pt
epoch: 16	train ppl: 176.609464112	val ppl: 175.001534904	best val: 175.001534904	time (s) spent in epoch: 146.84379887580872

EPOCH 17 ------------------
step: 10	loss: 2052.0125365257263	speed (wps):6108.943767924705
step: 142	loss: 25553.806128501892	speed (wps):6421.402247918411
step: 274	loss: 49735.3262591362	speed (wps):6434.207278000236
step: 406	loss: 73489.50229644775	speed (wps):6438.840320423039
step: 538	loss: 97453.64462137222	speed (wps):6440.699293387099
step: 670	loss: 121443.29720973969	speed (wps):6441.912489317934
step: 802	loss: 145005.86624145508	speed (wps):6442.670408793641
step: 934	loss: 168844.45105314255	speed (wps):6443.133092253047
step: 1066	loss: 192673.82298707962	speed (wps):6443.309439265917
step: 1198	loss: 216194.71528053284	speed (wps):6443.730751076478
Saving model parameters to best_params.pt
epoch: 17	train ppl: 172.368278988	val ppl: 172.124767035	best val: 172.124767035	time (s) spent in epoch: 146.78831243515015

EPOCH 18 ------------------
step: 10	loss: 2038.8826131820679	speed (wps):6274.717579682407
step: 142	loss: 25413.84114265442	speed (wps):6434.524732646424
step: 274	loss: 49497.144639492035	speed (wps):6440.957122693882
step: 406	loss: 73116.88483953476	speed (wps):6442.854880652434
step: 538	loss: 96953.16178798676	speed (wps):6443.900435407994
step: 670	loss: 120881.10119819641	speed (wps):6444.602904946588
step: 802	loss: 144363.22559833527	speed (wps):6444.657636600267
step: 934	loss: 168124.9014568329	speed (wps):6445.020332565788
step: 1066	loss: 191852.30990886688	speed (wps):6445.370401007059
step: 1198	loss: 215239.02469873428	speed (wps):6445.619765439146
Saving model parameters to best_params.pt
epoch: 18	train ppl: 168.521361976	val ppl: 170.470808161	best val: 170.470808161	time (s) spent in epoch: 146.8322401046753

EPOCH 19 ------------------
step: 10	loss: 2037.0629286766052	speed (wps):6137.366261165688
step: 142	loss: 25315.830538272858	speed (wps):6421.496729516706
step: 274	loss: 49301.543617248535	speed (wps):6434.612318927898
step: 406	loss: 72825.97791433334	speed (wps):6438.731658501604
step: 538	loss: 96553.93414258957	speed (wps):6441.156535738115
step: 670	loss: 120346.52167320251	speed (wps):6442.721758987728
step: 802	loss: 143715.30960083008	speed (wps):6443.484256487986
step: 934	loss: 167390.3800392151	speed (wps):6443.926972012959
step: 1066	loss: 191060.53389310837	speed (wps):6444.216232060499
step: 1198	loss: 214343.58122348785	speed (wps):6444.510517973171
Saving model parameters to best_params.pt
epoch: 19	train ppl: 164.892082815	val ppl: 168.684843721	best val: 168.684843721	time (s) spent in epoch: 146.85900902748108

EPOCH 20 ------------------
step: 10	loss: 2022.5377297401428	speed (wps):6116.196392376452
step: 142	loss: 25217.921438217163	speed (wps):6420.605452404515
step: 274	loss: 49123.53006362915	speed (wps):6433.194001720525
step: 406	loss: 72536.82031154633	speed (wps):6437.7305593468145
step: 538	loss: 96138.36081266403	speed (wps):6439.810029964545
step: 670	loss: 119816.86625957489	speed (wps):6441.389439444331
step: 802	loss: 143082.55928754807	speed (wps):6442.46514809409
step: 934	loss: 166661.4205479622	speed (wps):6443.2532732944555
step: 1066	loss: 190196.30014419556	speed (wps):6443.911739121817
step: 1198	loss: 213396.6931128502	speed (wps):6444.224833984175
Saving model parameters to best_params.pt
epoch: 20	train ppl: 161.265518875	val ppl: 167.486135793	best val: 167.486135793	time (s) spent in epoch: 146.76565074920654

EPOCH 21 ------------------
step: 10	loss: 2014.1538262367249	speed (wps):6307.735281738487
step: 142	loss: 25094.088864326477	speed (wps):6436.937441758418
step: 274	loss: 48915.00916957855	speed (wps):6442.755271779073
step: 406	loss: 72249.53863620758	speed (wps):6444.653071956313
step: 538	loss: 95780.14189958572	speed (wps):6445.281307853384
step: 670	loss: 119382.16084957123	speed (wps):6445.875539387169
step: 802	loss: 142548.313331604	speed (wps):6446.067867841016
step: 934	loss: 166036.11840248108	speed (wps):6446.142521017124
step: 1066	loss: 189497.84081697464	speed (wps):6446.439739428179
step: 1198	loss: 212590.74118852615	speed (wps):6446.536691701685
Saving model parameters to best_params.pt
epoch: 21	train ppl: 158.271975422	val ppl: 165.872807139	best val: 165.872807139	time (s) spent in epoch: 146.76520776748657

EPOCH 22 ------------------
step: 10	loss: 2006.2455677986145	speed (wps):6281.145133183968
step: 142	loss: 25016.975467205048	speed (wps):6433.607160799974
step: 274	loss: 48744.155859947205	speed (wps):6440.280442759454
step: 406	loss: 71974.3801355362	speed (wps):6442.579073035702
step: 538	loss: 95419.2532157898	speed (wps):6443.870627791106
step: 670	loss: 118939.66490745544	speed (wps):6444.361440737297
step: 802	loss: 142046.22979402542	speed (wps):6445.116956068563
step: 934	loss: 165481.6658091545	speed (wps):6445.322369405276
step: 1066	loss: 188889.17246341705	speed (wps):6445.7051901221475
step: 1198	loss: 211908.22868824005	speed (wps):6445.88110569107
epoch: 22	train ppl: 155.675400997	val ppl: 167.874163461	best val: 165.872807139	time (s) spent in epoch: 146.65216541290283

EPOCH 23 ------------------
step: 10	loss: 2005.411536693573	speed (wps):6311.560368983123
step: 142	loss: 24952.638380527496	speed (wps):6434.519111648262
step: 274	loss: 48577.02905416489	speed (wps):6440.313731408501
step: 406	loss: 71707.27687597275	speed (wps):6442.592584974625
step: 538	loss: 95073.86940956116	speed (wps):6443.919800011099
step: 670	loss: 118509.43069458008	speed (wps):6444.706524654941
step: 802	loss: 141520.55432796478	speed (wps):6445.059623446976
step: 934	loss: 164827.65833377838	speed (wps):6445.52591219915
step: 1066	loss: 188127.58657455444	speed (wps):6445.82721876037
step: 1198	loss: 211072.97038555145	speed (wps):6446.1288101424
epoch: 23	train ppl: 152.672856449	val ppl: 166.526907814	best val: 165.872807139	time (s) spent in epoch: 146.64857292175293

EPOCH 24 ------------------
step: 10	loss: 1990.649015903473	speed (wps):6285.265829426305
step: 142	loss: 24823.37842941284	speed (wps):6435.576031958484
step: 274	loss: 48397.51196146011	speed (wps):6441.082291439897
step: 406	loss: 71456.41869783401	speed (wps):6442.882775357279
step: 538	loss: 94752.77461051941	speed (wps):6443.6789052832955
step: 670	loss: 118095.79576015472	speed (wps):6444.039811699816
step: 802	loss: 141052.78799772263	speed (wps):6444.729778068966
step: 934	loss: 164299.1757774353	speed (wps):6445.03482847679
step: 1066	loss: 187537.37271547318	speed (wps):6445.308048801521
step: 1198	loss: 210389.58884000778	speed (wps):6445.615965226903
Saving model parameters to best_params.pt
epoch: 24	train ppl: 150.196964719	val ppl: 164.379430559	best val: 164.379430559	time (s) spent in epoch: 146.77715420722961

EPOCH 25 ------------------
step: 10	loss: 1993.2341718673706	speed (wps):6279.374320706329
step: 142	loss: 24751.454520225525	speed (wps):6434.514378183743
step: 274	loss: 48244.56208229065	speed (wps):6441.446109995023
step: 406	loss: 71222.1784901619	speed (wps):6443.2624522123315
step: 538	loss: 94422.44230031967	speed (wps):6444.404897676525
step: 670	loss: 117720.4738688469	speed (wps):6445.158147316082
step: 802	loss: 140616.8345785141	speed (wps):6445.324975981946
step: 934	loss: 163807.03968048096	speed (wps):6445.515621251211
step: 1066	loss: 186956.813082695	speed (wps):6445.545555893948
step: 1198	loss: 209720.74719667435	speed (wps):6445.753294996205
Saving model parameters to best_params.pt
epoch: 25	train ppl: 147.805044975	val ppl: 162.768801938	best val: 162.768801938	time (s) spent in epoch: 146.82580661773682

EPOCH 26 ------------------
step: 10	loss: 1984.0552735328674	speed (wps):6108.79124163251
step: 142	loss: 24675.32784461975	speed (wps):6420.352039429434
step: 274	loss: 48089.52205181122	speed (wps):6433.530938977556
step: 406	loss: 71011.28599643707	speed (wps):6438.206406849282
step: 538	loss: 94164.64599609375	speed (wps):6440.254067473668
step: 670	loss: 117374.9394083023	speed (wps):6441.651195984455
step: 802	loss: 140141.78867578506	speed (wps):6442.766626498066
step: 934	loss: 163228.01754951477	speed (wps):6443.468920807832
step: 1066	loss: 186298.62225055695	speed (wps):6443.949542348598
step: 1198	loss: 208997.29584217072	speed (wps):6444.342697975202
Saving model parameters to best_params.pt
epoch: 26	train ppl: 145.210391386	val ppl: 162.425316906	best val: 162.425316906	time (s) spent in epoch: 146.7652337551117

EPOCH 27 ------------------
step: 10	loss: 1967.435450553894	speed (wps):6301.151180338839
step: 142	loss: 24539.301600456238	speed (wps):6436.011584917508
step: 274	loss: 47895.631482601166	speed (wps):6441.505260087605
step: 406	loss: 70726.96705579758	speed (wps):6443.441588789809
step: 538	loss: 93783.18743228912	speed (wps):6444.293942791051
step: 670	loss: 116910.20053386688	speed (wps):6444.965388202805
step: 802	loss: 139643.0088353157	speed (wps):6445.192367462041
step: 934	loss: 162668.3044552803	speed (wps):6445.606848623476
step: 1066	loss: 185681.08812332153	speed (wps):6445.864991413101
step: 1198	loss: 208307.85269260406	speed (wps):6445.95276168334
Saving model parameters to best_params.pt
epoch: 27	train ppl: 142.981896857	val ppl: 162.008624661	best val: 162.008624661	time (s) spent in epoch: 146.82526302337646

EPOCH 28 ------------------
step: 10	loss: 1971.15407705307	speed (wps):6262.360827606854
step: 142	loss: 24495.75983285904	speed (wps):6432.587943402518
step: 274	loss: 47776.52046203613	speed (wps):6439.276499636678
step: 406	loss: 70520.00182151794	speed (wps):6441.545421434873
step: 538	loss: 93505.06552934647	speed (wps):6442.795796173297
step: 670	loss: 116592.44099140167	speed (wps):6443.613551982199
step: 802	loss: 139234.1759800911	speed (wps):6444.134584390298
step: 934	loss: 162215.9518456459	speed (wps):6444.565787194659
step: 1066	loss: 185149.50739860535	speed (wps):6444.853784022208
step: 1198	loss: 207684.30682897568	speed (wps):6445.082492944485
epoch: 28	train ppl: 140.742776062	val ppl: 168.197080328	best val: 162.008624661	time (s) spent in epoch: 146.6690809726715

EPOCH 29 ------------------
step: 10	loss: 1974.2335200309753	speed (wps):6305.518534680103
step: 142	loss: 24432.379777431488	speed (wps):6435.24193423295
step: 274	loss: 47643.559024333954	speed (wps):6441.718486943781
step: 406	loss: 70339.77558374405	speed (wps):6443.0457019332025
step: 538	loss: 93259.8522901535	speed (wps):6444.061626973095
step: 670	loss: 116262.00090169907	speed (wps):6444.59989022164
step: 802	loss: 138829.32854652405	speed (wps):6445.109714553318
step: 934	loss: 161736.53553247452	speed (wps):6445.302878398071
step: 1066	loss: 184598.0724477768	speed (wps):6445.4597940553895
step: 1198	loss: 207098.30538272858	speed (wps):6445.644714769933
Saving model parameters to best_params.pt
epoch: 29	train ppl: 138.893215428	val ppl: 159.711906147	best val: 159.711906147	time (s) spent in epoch: 146.83402729034424

EPOCH 30 ------------------
step: 10	loss: 1952.9485201835632	speed (wps):6131.459932671183
step: 142	loss: 24340.67761182785	speed (wps):6420.649146318648
step: 274	loss: 47486.79727554321	speed (wps):6433.402218935611
step: 406	loss: 70090.22407770157	speed (wps):6437.679610823969
step: 538	loss: 92933.13875436783	speed (wps):6439.728845049443
step: 670	loss: 115866.24035835266	speed (wps):6441.202907714768
step: 802	loss: 138404.06817913055	speed (wps):6442.3442759247555
step: 934	loss: 161249.73632335663	speed (wps):6443.144661014453
step: 1066	loss: 184053.6428809166	speed (wps):6443.576632644956
step: 1198	loss: 206460.0217986107	speed (wps):6443.856110687964
epoch: 30	train ppl: 136.759166938	val ppl: 160.991331483	best val: 159.711906147	time (s) spent in epoch: 146.6973259449005

EPOCH 31 ------------------
step: 10	loss: 1957.236852645874	speed (wps):6312.618849738591
step: 142	loss: 24329.65402841568	speed (wps):6434.428683957502
step: 274	loss: 47374.94189500809	speed (wps):6441.310392646018
step: 406	loss: 69918.9880156517	speed (wps):6443.02325995815
step: 538	loss: 92709.35868263245	speed (wps):6444.087893854187
step: 670	loss: 115576.4164686203	speed (wps):6444.345546137746
step: 802	loss: 138011.40940904617	speed (wps):6444.9289990891275
step: 934	loss: 160769.8367381096	speed (wps):6444.920164273987
step: 1066	loss: 183514.88004922867	speed (wps):6444.95253697635
step: 1198	loss: 205849.82667446136	speed (wps):6445.202866390022
epoch: 31	train ppl: 134.751572646	val ppl: 161.784741382	best val: 159.711906147	time (s) spent in epoch: 146.67014718055725

EPOCH 32 ------------------
step: 10	loss: 1945.8277297019958	speed (wps):6288.032697004436
step: 142	loss: 24213.408660888672	speed (wps):6435.000876699294
step: 274	loss: 47208.092782497406	speed (wps):6441.436243186949
step: 406	loss: 69690.68237304688	speed (wps):6443.20971374474
step: 538	loss: 92398.90975475311	speed (wps):6444.253949582744
step: 670	loss: 115199.09620046616	speed (wps):6444.89905744446
step: 802	loss: 137579.75715637207	speed (wps):6445.200084895771
step: 934	loss: 160284.84838485718	speed (wps):6445.4245931941
step: 1066	loss: 182967.1703839302	speed (wps):6445.716224366114
step: 1198	loss: 205228.94567489624	speed (wps):6445.664046503416
epoch: 32	train ppl: 132.963553941	val ppl: 160.124074222	best val: 159.711906147	time (s) spent in epoch: 146.65923738479614

EPOCH 33 ------------------
step: 10	loss: 1938.6030316352844	speed (wps):6308.176353934497
step: 142	loss: 24115.52170753479	speed (wps):6437.157523648035
step: 274	loss: 47103.477454185486	speed (wps):6442.164720997517
step: 406	loss: 69529.6812915802	speed (wps):6443.862786601195
step: 538	loss: 92168.39753627777	speed (wps):6445.071730934701
step: 670	loss: 114888.84263753891	speed (wps):6445.769245878917
step: 802	loss: 137207.63326883316	speed (wps):6445.807159485905
step: 934	loss: 159835.26277780533	speed (wps):6446.024880989649
step: 1066	loss: 182461.2763285637	speed (wps):6446.095894334754
step: 1198	loss: 204671.71513080597	speed (wps):6446.294492151896
epoch: 33	train ppl: 131.124521737	val ppl: 161.602441116	best val: 159.711906147	time (s) spent in epoch: 146.6494278907776

EPOCH 34 ------------------
step: 10	loss: 1925.4260110855103	speed (wps):6283.3741120512
step: 142	loss: 24063.41699361801	speed (wps):6433.11160732228
step: 274	loss: 46973.809299468994	speed (wps):6440.2994501249395
step: 406	loss: 69331.42281532288	speed (wps):6442.370253052534
step: 538	loss: 91896.78749799728	speed (wps):6443.228623968776
step: 670	loss: 114586.3675236702	speed (wps):6443.789958998789
step: 802	loss: 136818.49967956543	speed (wps):6444.691813309627
step: 934	loss: 159422.68050432205	speed (wps):6444.824613888274
step: 1066	loss: 181973.27278614044	speed (wps):6445.036680911843
step: 1198	loss: 204127.16137886047	speed (wps):6445.23907016444
Saving model parameters to best_params.pt
epoch: 34	train ppl: 129.409420071	val ppl: 159.038886311	best val: 159.038886311	time (s) spent in epoch: 146.79787302017212

EPOCH 35 ------------------
step: 10	loss: 1929.015212059021	speed (wps):6300.537775164487
step: 142	loss: 24008.494741916656	speed (wps):6435.535389933132
step: 274	loss: 46871.8887257576	speed (wps):6441.207619208571
step: 406	loss: 69177.3630642891	speed (wps):6443.234693187977
step: 538	loss: 91697.49029636383	speed (wps):6443.813689711957
step: 670	loss: 114351.70652866364	speed (wps):6444.045355302381
step: 802	loss: 136550.87706565857	speed (wps):6444.603905908671
step: 934	loss: 159082.15131521225	speed (wps):6445.138662263392
step: 1066	loss: 181566.01873874664	speed (wps):6445.317914744344
step: 1198	loss: 203654.68329191208	speed (wps):6445.551633742518
Saving model parameters to best_params.pt
epoch: 35	train ppl: 127.920441427	val ppl: 158.650648358	best val: 158.650648358	time (s) spent in epoch: 146.83213639259338

EPOCH 36 ------------------
step: 10	loss: 1925.4300665855408	speed (wps):6118.166096422075
step: 142	loss: 23946.818380355835	speed (wps):6421.857985214624
step: 274	loss: 46755.035717487335	speed (wps):6433.69339707204
step: 406	loss: 68968.37244987488	speed (wps):6438.263572940968
step: 538	loss: 91425.0897359848	speed (wps):6440.191532133926
step: 670	loss: 113990.26174068451	speed (wps):6441.554245857216
step: 802	loss: 136125.43159723282	speed (wps):6442.356563625339
step: 934	loss: 158608.1307530403	speed (wps):6443.097448631047
step: 1066	loss: 181034.93273496628	speed (wps):6443.614498208459
step: 1198	loss: 203043.19805145264	speed (wps):6443.663897756628
Saving model parameters to best_params.pt
epoch: 36	train ppl: 126.036199957	val ppl: 158.605059978	best val: 158.605059978	time (s) spent in epoch: 146.86993956565857

EPOCH 37 ------------------
step: 10	loss: 1922.2670102119446	speed (wps):6291.002966085105
step: 142	loss: 23899.102368354797	speed (wps):6435.195378343046
step: 274	loss: 46623.71502161026	speed (wps):6439.985997039725
step: 406	loss: 68814.3780207634	speed (wps):6442.634996852862
step: 538	loss: 91205.20321130753	speed (wps):6443.595628799069
step: 670	loss: 113717.51569509506	speed (wps):6444.452319721343
step: 802	loss: 135802.4737882614	speed (wps):6444.908262474814
step: 934	loss: 158198.10012340546	speed (wps):6445.253954673366
step: 1066	loss: 180599.94539260864	speed (wps):6445.5117256460935
step: 1198	loss: 202550.11401891708	speed (wps):6445.685679771231
epoch: 37	train ppl: 124.587738608	val ppl: 159.834161002	best val: 158.605059978	time (s) spent in epoch: 146.65922737121582

EPOCH 38 ------------------
step: 10	loss: 1905.6963539123535	speed (wps):6312.48312723773
step: 142	loss: 23810.033156871796	speed (wps):6436.635667831077
step: 274	loss: 46509.31719303131	speed (wps):6442.322989090787
step: 406	loss: 68607.98446178436	speed (wps):6443.647142565077
step: 538	loss: 90921.95425510406	speed (wps):6444.646109143282
step: 670	loss: 113400.39109706879	speed (wps):6445.032837821539
step: 802	loss: 135420.0830435753	speed (wps):6445.350825235397
step: 934	loss: 157799.17418718338	speed (wps):6445.834943487739
step: 1066	loss: 180164.5476770401	speed (wps):6445.988365710783
step: 1198	loss: 202082.49478816986	speed (wps):6446.02025267471
epoch: 38	train ppl: 123.248875604	val ppl: 158.606856352	best val: 158.605059978	time (s) spent in epoch: 146.65419960021973

EPOCH 39 ------------------
step: 10	loss: 1913.4196949005127	speed (wps):6309.519663144701
step: 142	loss: 23785.000491142273	speed (wps):6437.038993370269
step: 274	loss: 46424.1660118103	speed (wps):6441.993456849336
step: 406	loss: 68503.27829360962	speed (wps):6443.4149052857965
step: 538	loss: 90798.80816221237	speed (wps):6444.287828311704
step: 670	loss: 113199.50362205505	speed (wps):6444.607795974882
step: 802	loss: 135153.98002386093	speed (wps):6445.208789055534
step: 934	loss: 157451.55690193176	speed (wps):6445.251170295659
step: 1066	loss: 179736.65125131607	speed (wps):6445.472511647956
step: 1198	loss: 201590.12141942978	speed (wps):6445.683531780699
Saving model parameters to best_params.pt
epoch: 39	train ppl: 121.729820978	val ppl: 158.328454003	best val: 158.328454003	time (s) spent in epoch: 146.81179761886597

DONE